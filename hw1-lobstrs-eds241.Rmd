---
title: "Assignment 1: California Spiny Lobster Abundance (*Panulirus Interruptus*)"
subtitle: "Assessing the Impact of Marine Protected Areas (MPAs) at 5 Reef Sites in Santa Barbara County"
author: "Eva Newby"
date: "1/8/2024 (Due 1/26), Regrade due 2/10"
output: 
    html_document:
      theme: flatly
    pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE, warning = FALSE, message = FALSE )
```

------------------------------------------------------------------------

![](figures/spiny2.jpg)

------------------------------------------------------------------------

### Assignment instructions:

-   Working with partners to troubleshoot code and concepts is encouraged! If you work with a partner, please list their name next to yours at the top of your assignment so Annie and I can easily see who collaborated.

-   All written responses must be written independently (**in your own words**).

-   Please follow the question prompts carefully and include only the information each question asks in your submitted responses.

-   Submit both your knitted document and the associated `RMarkdown` or `Quarto` file.

-   Your knitted presentation should meet the quality you'd submit to research colleagues or feel confident sharing publicly. Refer to the rubric for details about presentation standards.

**Assignment submission (YOUR NAME):** Eva Newby \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

------------------------------------------------------------------------

```{r}
# Load libraries
library(tidyverse)
library(here)
library(janitor)
library(estimatr)  
library(performance)
library(jtools)
library(gt)
library(gtsummary)
library(MASS) ## NOTE: The `select()` function is masked. Use: `dplyr::select()` ##
library(interactions) 
library(ggridges)
library(ggbeeswarm)

```

------------------------------------------------------------------------

#### DATA SOURCE:

Reed D. 2019. SBC LTER: Reef: Abundance, size and fishing effort for California Spiny Lobster (Panulirus interruptus), ongoing since 2012. Environmental Data Initiative. <https://doi.org/10.6073/pasta/a593a675d644fdefb736750b291579a0>. Dataset accessed 11/17/2019.

------------------------------------------------------------------------

### **Introduction**

You're about to dive into some deep data collected from five reef sites in Santa Barbara County, all about the abundance of California spiny lobsters! ðŸ¦ž Data was gathered by divers annually from 2012 to 2018 across Naples, Mohawk, Isla Vista, Carpinteria, and Arroyo Quemado reefs.

Why lobsters? Well, this sample provides an opportunity to evaluate the impact of Marine Protected Areas (MPAs) established on January 1, 2012 (Reed, 2019). Of these five reefs, Naples, and Isla Vista are MPAs, while the other three are not protected (non-MPAs). Comparing lobster health between these protected and non-protected areas gives us the chance to study how commercial and recreational fishing might impact these ecosystems.

We will consider the MPA sites the `treatment` group and use regression methods to explore whether protecting these reefs really makes a difference compared to non-MPA sites (our control group). In this assignment, weâ€™ll think deeply about which causal inference assumptions hold up under the research design and identify where they fall short.

Letâ€™s break it down step by step and see what the data reveals! ðŸ“Š

![](figures/map-5reefs.png)

------------------------------------------------------------------------

Step 1: Anticipating potential sources of selection bias

**a.** Do the control sites (Arroyo Quemado, Carpenteria, and Mohawk) provide a strong counterfactual for our treatment sites (Naples, Isla Vista)? Write a paragraph making a case for why this comparison is centris paribus or whether selection bias is likely (be specific!).

The control sites may not provide a perfect counterfactual for the treatment sites due to potential selection bias. For example, using the centris paribus logic in this case means that the single difference between the two groups is whether or not they are an MPA. However, there may be other differences between the habitats, such as microclimate and/or proximity to town/cities. One can make a case that centris paribus logic may apply as the sites are relatively close together.

------------------------------------------------------------------------

Step 2: Read & wrangle data

**a.** Read in the raw data. Name the data.frame (`df`) `rawdata`

**b.** Use the function `clean_names()` from the `janitor` package

```{r}
# HINT: check for coding of missing values (`na = "-99999"`)

rawdata <- read_csv(here("data", 'spiny_abundance_sb_18.csv'), na = "-99999") %>%
    clean_names()
    
```

**c.** Create a new `df` named `tidyata`. Using the variable `site` (reef location) create a new variable `reef` as a `factor` and add the following labels in the order listed (i.e., re-order the `levels`):

```         
"Arroyo Quemado", "Carpenteria", "Mohawk", "Isla Vista",  "Naples"
```

```{r}
# Add long lables to our sites and save in a col named reef
tidydata <- rawdata %>% 
    mutate(reef = factor(site, 
                         levels = c("AQUE", "CARP", "MOHK",     "IVEE", "NAPL"), 
                         labels = c("Arroyo Quemado", "Carpenteria", "Mohawk", 
                                    "Isla Vista",  "Naples")))
```

Create new `df` named `spiny_counts`

**d.** Create a new variable `counts` to allow for an analysis of lobster counts where the unit-level of observation is the total number of observed lobsters per `site`, `year` and `transect`.

-   Create a variable `mean_size` from the variable `size_mm`
-   NOTE: The variable `counts` should have values which are integers (whole numbers).
-   Make sure to account for missing cases (`na`)!

**e.** Create a new variable `mpa` with levels `MPA` and `non_MPA`. For our regression analysis create a numerical variable `treat` where MPA sites are coded `1` and non_MPA sites are coded `0`

```{r}
#HINT(d): Use `group_by()` & `summarize()` to provide the total number of lobsters observed at each site-year-transect row-observation. 

#HINT(e): Use `case_when()` to create the 3 new variable columns

# assign each site either mpa or non-mpa, and 1 or 0
spiny_counts <- tidydata %>% 
    group_by(site, year, transect) %>% 
    summarise(count = sum(count, na.rm = TRUE), mean_size = mean(size_mm, na.rm = TRUE)) %>% 
    mutate(mpa = case_when(site %in% c("IVEE", "NAPL") ~ "MPA",
                           .default = "non_MPA")) %>% 
    mutate(treat = case_when(mpa == "MPA" ~ 1,
                             .default = 0)) %>% 
    ungroup()
```

> NOTE: This step is crucial to the analysis. Check with a friend or come to TA/instructor office hours to make sure the counts are coded correctly!

------------------------------------------------------------------------

Step 3: Explore & visualize data

**a.** Take a look at the data! Get familiar with the data in each `df` format (`tidydata`, `spiny_counts`)

```{r}
# Data Exploration
# First 5 rows of each
print(head(spiny_counts))
print(head(tidydata))

# Datatypes of each column
print(spiny_counts %>% summarise_all(class))
print(tidydata %>% summarise_all(class))
```

**b.** We will focus on the variables `count`, `year`, `site`, and `treat`(`mpa`) to model lobster abundance. Create the following 4 plots using a different method each time from the 6 options provided. Add a layer (`geom`) to each of the plots including informative descriptive statistics (you choose; e.g., mean, median, SD, quartiles, range). Make sure each plot dimension is clearly labeled (e.g., axes, groups).

-   [Density plot](https://r-charts.com/distribution/density-plot-group-ggplot2)
-   [Ridge plot](https://r-charts.com/distribution/ggridges/)
-   [Jitter plot](https://ggplot2.tidyverse.org/reference/geom_jitter.html)
-   [Violin plot](https://r-charts.com/distribution/violin-plot-group-ggplot2)
-   [Histogram](https://r-charts.com/distribution/histogram-density-ggplot2/)
-   [Beeswarm](https://r-charts.com/distribution/beeswarm/)

Create plots displaying the distribution of lobster **counts**:

1)  grouped by reef site
2)  grouped by MPA status
3)  grouped by year

Create a plot of lobster **size** :

4)  You choose the grouping variable(s)!

```{r}
# plot 1: Beeswarm Plot grouped by MPA status
spiny_counts %>% 
ggplot(aes(x = treat, y = count, color = mpa)) +
    geom_beeswarm(alpha = 0.5) +
    labs(title = 'Beeswarm Plot of Lobster Count per MPA status',
         x = 'MPA status',
         y = 'Lobster Count')+
    theme_minimal()+
    geom_boxplot(aes(x = treat, y = count, color = mpa), alpha =0.5) # Statistical summary present in boxplot
```

```{r}
# plot 2: Ridge plot grouped by Reef

spiny_counts %>% 
ggplot(aes(x = count, y = site, fill = site))+
    geom_density_ridges(alpha = 0.8)+
     stat_summary(
        fun = median, 
        geom = "point",
        aes(shape = 'Median'), # Add in summary statistic, median
        color = "black", 
        size = 2
    )+
    theme_minimal() + 
    theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
     labs(title = 'Ridge Plot of Lobster Count per Reef',
         x = 'Lobster Count',
         y = 'Reef Site')
```

```{r}
# Plot 3: Density plot grouped by year

spiny_counts %>% 
ggplot(
    aes(
        x = count, 
        fill = factor(year))
    ) + 
    geom_density(alpha = 0.6) +
    labs(title = "Density Plot of Lobster Counts by Year",
         x = "Lobster Count",
         y = "Lobster Density",
         fill = 'Year',
         color = 'Year') +
    theme_minimal()+
    geom_vline(
        aes(xintercept = mean(count), # Add mean 
            color = "Mean Line"), 
        linewidth = 1, 
        linetype = 'dashed')
```

```{r}
# Plot 4: Jitter plot grouped by lobster size *updated*

spiny_counts %>% 
ggplot(aes(x = site,
           y = mean_size,
           color = site))+
    geom_jitter(alpha = 0.7)+
    geom_boxplot(alpha = 0.5) + # summary statistics present in boxplot
    labs(title = "Jitter Plot of Mean Lobster Size per MPA")
```

**c.** Compare means of the outcome by treatment group. Using the `tbl_summary()` function from the package [`gt_summary`](https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html)

```{r}
# USE: gt_summary::tbl_summary()

spiny_counts %>%
  dplyr::select(count, treat) %>%
  tbl_summary(
    by = treat,  # Group by MPA treatment status (0 or 1)
    statistic = list(all_continuous() ~ "{mean}"),  # Show mean 
    missing = "no"  # remove missing values
  ) %>%
  add_p(test = list(count ~ "t.test"))  # Perform t-test to compare means

```

------------------------------------------------------------------------

Step 4: OLS regression- building intuition

**a.** Start with a simple OLS estimator of lobster counts regressed on treatment. Use the function `summ()` from the [`jtools`](https://jtools.jacob-long.com/) package to print the OLS output

**b.** Interpret the intercept & predictor coefficients *in your own words*. Use full sentences and write your interpretation of the regression results to be as clear as possible to a non-academic audience.

```{r}
# NOTE: We will not evaluate/interpret model fit in this assignment (e.g., R-square)

m1_ols <- lm(count ~ treat, spiny_counts)

summ(m1_ols, model.fit = FALSE) 

```

Interpretation: On average, there are 22.73 lobsters counted in non-MPA sites (intercept, or Beta 0) whereas MPA sites have 5.36 more lobsters on average compared to non-MPA sites (Beta 1). However, this difference could be due to chance (as our p-value is 0.3, not statistically significant).

**c.** Check the model assumptions using the `check_model` function from the `performance` package

**d.** Explain the results of the 4 diagnostic plots. Why are we getting this result?

```{r}
check_model(m1_ols,  check = "qq" )
```

Explanation *updated*: The deviations from the lines suggest the data is not normally distributed (it is skewed). QQ plots assess the normality of residuals, where each dot is a quantile of a sampled residual and the line represents expected quantiles. If the dots followed the line more closely, it would indicate that the data is normally distributed.

```{r}
check_model(m1_ols, check = "normality")
```

Explanation *updated*: The right skew suggests that the data is not normally distributed. The blue region represents the distribution of the residuals, while the green line represents an expected normal distribution. If the residuals were normally distributed, their density would closely follow the green curve.

```{r}
check_model(m1_ols, check = "homogeneity")
```

Explanation: The graph shows a more U-shaped curve which indicates that the variance of residuals is not constant across fitted values (heteroscedasticity), and this violates one of the assumptions of OLS. Additionally, the residuals are more extreme at either end, suggesting that the model predictions are less accurate for extreme values.

```{r}
check_model(m1_ols, check = "pp_check")
```

Explanation: As our observed data doesn't seem to match our model-predicted data that well, alternative models should be explored.

------------------------------------------------------------------------

Step 5: Fitting GLMs

**a.** Estimate a Poisson regression model using the `glm()` function

**b.** Interpret the predictor coefficient in your own words. Use full sentences and write your interpretation of the results to be as clear as possible to a non-academic audience.

On average, the expected lobster count in non-MPA areas is 22.729 lobsters. On average, the expected lobster count in MPA areas is 1.235 times greater than in non-MPA areas, meaning MPA areas have an approx 23.6% higher lobster count than non-MPA areas.

**c.** Explain the statistical concept of dispersion and overdispersion in the context of this model.

Dispersion refers to how far away data is from the mean. An assumption of the poisson model is that the variance and the mean are equal, and that the data is not overdispersed (variance greater than the mean). If the variance is greater than the mean, then a negative binomial regression should be used instead of poisson.

**d.** Compare results with previous model, explain change in the significance of the treatment effect

It is clear that OLS is not the best model for our data, as our data violates several of OLS' assumptions (such as normal distribution). The poisson model assesses a log-linear relationship, which appears to be more accurate for the data. However, depending on whether or not there is overdispersion, the standard errors in the poisson model may be inaccurate. This could make it seem that the change in significance was larger than it actually was.

```{r}
#HINT1: Incidence Ratio Rate (IRR): Exponentiation of beta returns coefficient which is interpreted as the 'percent change' for a one unit increase in the predictor 

#HINT2: For the second glm() argument `family` use the following specification option `family = poisson(link = "log")`

m2_pois <- glm(count ~ treat, spiny_counts, family = poisson(link = 'log'))

summary(m2_pois)

# Exponentiate the coefficients for more clear interpretation
exp(coef(m2_pois))

# Percentage change
(1.235956 - 1) * 100
```

**e.** Check the model assumptions. Explain results.

The key model assumptions for poisson is that the data must represent count data, the mean equals the variance (no overdispersion), there is a log-linear relationship, zero-inflation (no zero counts in the data), and observations must be independent of each other.

**f.** Conduct tests for over-dispersion & zero-inflation. Explain results.

```{r}
check_model(m2_pois)
```

```{r}
check_overdispersion(m2_pois)
```

```{r}
check_zeroinflation(m2_pois)
```

Explanation: The results show that there is probable zero-inflation and overdispersion. Zero-inflation describes the amount of zeroes in a dataset being higher than expected, and is common in ecological data suggesting absence. Overdispersion is when the variance is greater than the mean. Both of these results suggest that a poisson model is not the best fit.

**g.** Fit a negative binomial model using the function glm.nb() from the package `MASS` and check model diagnostics

**h.** In 1-2 sentences explain rationale for fitting this GLM model.

As overdispersion was found to be present in the last step, a negative binomial regression model is a better option for a more accurate fitting compared to a poisson model.

**i.** Interpret the treatment estimate result in your own words. Compare with results from the previous model.

This model appears to be a better fit than the poisson model, as overdispersion is not occurring; however, the model is still over-fitting zeros.

```{r}
# NOTE: The `glm.nb()` function does not require a `family` argument

m3_nb <- glm.nb(count ~ treat, spiny_counts)

summary(m3_nb)
```

```{r}
check_overdispersion(m3_nb)
```

```{r}
check_zeroinflation(m3_nb)
```

```{r}
check_predictions(m3_nb)
```

```{r}
check_model(m3_nb)
```

------------------------------------------------------------------------

Step 6: Compare models

**a.** Use the `export_summ()` function from the `jtools` package to look at the three regression models you fit side-by-side.

**c.** Write a short paragraph comparing the results. Is the treatment effect `robust` or stable across the model specifications.

There is variation in the treatment effect between the three models. The results of the OLS model show no statistically significant effect on lobster count in MPA vs non-MPA, where as both poisson and negative binomial regression both show statistically significant effects. The treatment effect is robust and/or stable across both the poisson and negative binomial regression analysis, but not OLS.

```{r}
# Position 3 models side by side
export_summs(list(m1_ols, m2_pois, m3_nb),
             model.names = c("OLS","Poisson", "NB"),
             statistics = "none")

```

------------------------------------------------------------------------

Step 7: Building intuition - fixed effects

**a.** Create new `df` with the `year` variable converted to a factor

**b.** Run the following negative binomial model using `glm.nb()`

-   Add fixed effects for `year` (i.e., dummy coefficients)

-   Include an interaction term between variables `treat` & `year` (`treat*year`)

**c.** Take a look at the regression output. Each coefficient provides a comparison or the difference in means for a specific sub-group in the data. Informally, describe the what the model has estimated at a conceptual level (NOTE: you do not have to interpret coefficients individually)

The model has estimated that the interaction between treatment and count vary depending on the year. Some years show that there is a strong positive correlation between MPA/non-MPA and count, whereas other years don't show that same pattern.

**d.** Explain why the main effect for treatment is negative? \*Does this result make sense?

This makes sense as there is still variation between treat and count per year. The first two years observed (2012 and 2013) show negative effects, however, they switch to positive for every year after that. This also makes sense, as the effects from MPA implementation, such as lack of lobster hunting, take a few years for lobster populations to bounce back and see the effects in the counts.

```{r}
ff_counts <- spiny_counts %>% 
    mutate(year=as_factor(year))
    
m5_fixedeffs <- glm.nb(
    count ~ 
        treat +
        year +
        treat*year,
    data = ff_counts)

summ(m5_fixedeffs, model.fit = FALSE)
```

**e.** Look at the model predictions: Use the `interact_plot()` function from package `interactions` to plot mean predictions by year and treatment status.

**f.** Re-evaluate your responses (c) and (b) above.

Based on the `interact_plot()`, it is easier to determine the differences in counts per year based on treat (MPA vs non-MPA). It appears that the largest difference is in 2018, with MPA receiving much higher counts than non-MPA. This makes sense looking at the results for the previous step, `treat:year2018` received the highest number, with 2.62, compared to all the other years.

```{r}

interact_plot(m5_fixedeffs, pred = year, modx = treat,
              outcome.scale = "response") # NOTE: 'link' = y-axis on log-scale

# HINT: Change `outcome.scale` to "response" to convert y-axis scale to counts
```

**g.** Using `ggplot()` create a plot in same style as the previous `interaction plot`, but displaying the original scale of the outcome variable (lobster counts). This type of plot is commonly used to show how the treatment effect changes across discrete time points (i.e., panel data).

The plot should haveâ€¦ - `year` on the x-axis - `counts` on the y-axis - `mpa` as the grouping variable

```{r}
# Hint 1: Group counts by `year` and `mpa` and calculate the `mean_count`

plot_counts <- spiny_counts %>% 
    group_by(year, mpa) %>% 
    summarize(mean_count = mean(count, na.rm = TRUE))

# Hint 2: Convert variable `year` to a factor
plot_counts$year <- as.factor(plot_counts$year)
    
# plot Lobster counts per year and MPA status
plot_counts %>% 
   ggplot(aes(x = year, 
              y = mean_count, 
              color = mpa, 
              group = mpa)) + 
    geom_line()+
    geom_point()+
    labs(x = "Year", 
       y = "Lobster Counts", 
       title = "Lobster Counts per Year and MPA Status",
       color = "MPA Status")+
    theme_minimal()+
    scale_color_manual(values = c("MPA" = "#F07167", "non_MPA" = "#7284A8"))  
```

------------------------------------------------------------------------

Step 8: Reconsider causal identification assumptions

a.  Discuss whether you think `spillover effects` are likely in this research context (see Glossary of terms; <https://docs.google.com/document/d/1RIudsVcYhWGpqC-Uftk9UTz3PIq6stVyEpT44EPNgpE/edit?usp=sharing>)

    Spillover effects suggest that "one unit's treatment affects a control unit's outcome". Given that there are location separations between the MPA and the non-MPA groups, and that the existence of MPAs within a certain area generally boost the biodiversity of the local ecosystem, I think it is fair to consider that there may be spillover effects. Lobsters don't know which areas are MPAs and which areas are not, and can roam freely between the two. This could potentially affect the lobster counts.

b.  Explain why spillover is an issue for the identification of causal effects

    Spillover effects complicate identifying the true effect of the treatment (in this example, MPA vs non-MPA). This makes it more difficult to identify causality for certain effects.

c.  How does spillover relate to impact in this research setting?'

    As mentioned in part a, the existence of MPAs may boost the general biodiversity of an area, even in non-MPA areas. This would affect the count amounts in both MPA and non-MPA areas.

d.  Discuss the following causal inference assumptions in the context of the MPA treatment effect estimator. Evaluate if each of the assumption are reasonable:

    1)  SUTVA: Stable Unit Treatment Value assumption - states that each entity can only be affected by the treatment it is receiving , and not the treatment of others. Lobster counts are affected by many other factors than MPA vs non-MPA status, such as food availability and disease. The SUTVA assumption is not valid for this case.
    2)  Excludability assumption - states that a variable used to create variation in the treatment affects the outcome only through its effect on the treatment, and not have any direct effect on the outcome. For this case, this assumption is reasonable as MPA itself doesn't directly affect lobster counts, it likely provides shelter from hunting, which may directly affect lobster counts.

------------------------------------------------------------------------

# EXTRA CREDIT

> Use the recent lobster abundance data with observations collected up until 2024 (`lobster_sbchannel_24.csv`) to run an analysis evaluating the effect of MPA status on lobster counts using the same focal variables.

a.  Create a new script for the analysis on the updated data

    ```{r}
    # Read in 2024 data
    rawdata24 <- read_csv(here("data", 'lobster_sbchannel_24.csv'), na = "-99999") %>%
        clean_names()

    # Tidy the data
    tidydata24 <- rawdata24 %>% 
        mutate(reef = factor(site, 
                             levels = c("AQUE", "CARP", "MOHK",     "IVEE", "NAPL"), 
                             labels = c("Arroyo Quemado", "Carpenteria", "Mohawk", 
                                        "Isla Vista",  "Naples")))

    # Assign each site either mpa or non-mpa, and 1 or 0
    spiny_counts24 <- tidydata24 %>% 
        group_by(site, year, transect) %>% 
        summarise(count = sum(count, na.rm = TRUE), mean_size = mean(size_mm, na.rm = TRUE)) %>% 
        mutate(mpa = case_when(site %in% c("IVEE", "NAPL") ~ "MPA",
                               .default = "non_MPA")) %>% 
        mutate(treat = case_when(mpa == "MPA" ~ 1,
                                 .default = 0)) %>% 
        ungroup()

    # Check the first 5 rows
    print(head(spiny_counts24))
    ```

b.  Run at least 3 regression models & assess model diagnostics

    ```{r}
    # OLS Regression
    m1_ols_24 <- lm(count ~ treat, spiny_counts24)

    print(summ(m1_ols_24, model.fit = FALSE))

    # Check model
    print(check_model(m1_ols_24, check = "normality"))
    print(check_model(m1_ols_24,  check = "qq" ))
    print(check_model(m1_ols_24, check = "homogeneity"))
    print(check_model(m1_ols_24, check = "pp_check"))
    ```

    ```{r}
    # Poisson Model
    m2_pois_24 <- glm(count ~ treat, spiny_counts24, family = poisson(link = 'log'))

    print(summary(m2_pois_24))

    # Check model assumptions
    print(check_model(m2_pois_24))
    print(check_overdispersion(m2_pois_24))
    print(check_zeroinflation(m2_pois_24))
    ```

    ```{r}
    # Negative Binomial Regression
    m3_nb_24 <- glm.nb(count ~ treat, spiny_counts24)

    print(summary(m3_nb_24))

    # Check model assumptions
    print(check_model(m3_nb_24))
    print(check_overdispersion(m3_nb_24))
    print(check_zeroinflation(m3_nb_24))
    print(check_predictions(m3_nb_24))
    ```

c.  Compare and contrast results with the analysis from the 2012-2018 data sample (\~ 2 paragraphs)

    For the OLS model, the 2012-2018 data intercepts were very similar, but the Beta 1 for the treatment increased from 5.36 to 7.72 for the 2024 data. The 2024 data was still not normally distributed, but was closer to a normal distribution compared to the 2012-2018 data. Thus, OLS is likely not the best model to use for the 2024 data, similar to the 2012-2018 data.

    For the Poisson model, the 2012-2018 data intercepts and the beta 1 for the treatment were very similar to 2024. The dispersion ration was slightly less for the 2024 data, but the amount of observed zeros almost doubled for the 2024 data. Thus, poisson is not the best model to use for the 2024 data, similar to the 2012-2018 data.

    The negative binomal regression model is a better fit for the 2024 data, the ratio of observed and predicted zeros is within the tolerance range (similarly to the 2012-2018 data). Both y-intercepts and beta 1s for the treatment are very similar between the datasets. The dispersion ratios were roughly the same between datasets; however, the amount of zeros is still quite large for the 2024 data. Regardless, this model type is the best fit out of the 3 types tested.

    ```{r}
    # Compare and contrast results for OLS
    print(summ(m1_ols, model.fit = FALSE))
    print(summ(m1_ols_24, model.fit = FALSE))
    print(check_model(m1_ols, check = "normality"))
    print(check_model(m1_ols_24, check = "normality"))


    # Compare and contrast results for Poisson
    print(summary(m2_pois))
    print(summary(m2_pois_24))
    print(check_overdispersion(m2_pois))
    print(check_overdispersion(m2_pois_24))
    print(check_zeroinflation(m2_pois))
    print(check_zeroinflation(m2_pois_24))

    # Compare and contrast results for Negative Binomial
    print(summary(m3_nb))
    print(summary(m3_nb_24))
    print(check_overdispersion(m3_nb))
    print(check_overdispersion(m3_nb_24))
    print(check_zeroinflation(m3_nb))
    print(check_zeroinflation(m3_nb_24))
    ```

------------------------------------------------------------------------

![](figures/spiny1.png)
